{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ***Engr.Muhammad Javed***"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 04. Flattening and Full Connection\n",
                "\n",
                "## 1. Theory: From Maps to Scores\n",
                "After several Convolution and Pooling layers, we end up with a high-level representation of the input (e.g., small 3D volume of feature maps).\n",
                "\n",
                "However, standard **Fully Connected (Dense)** neural networks (like Multi-Layer Perceptrons) require a **1D vector** as input.\n",
                "\n",
                "### Flattening\n",
                "This operation converts a 2D matrix (or 3D tensor) into a long 1D vector.\n",
                "Example: A $5 \\times 5$ image becomes a vector of size $25$.\n",
                "\n",
                "### Fully Connected Layer (Dense Layer)\n",
                "Once flattened, the vector is fed into a Dense layer where every input is connected to every neuron. This part of the network acts as the **Classifier**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Shape before flattening: (10, 5, 5, 3)\n"
                    ]
                }
            ],
            "source": [
                "import numpy as np\n",
                "\n",
                "# Imagine we have the output from a pooling layer\n",
                "# Let's say we have 10 images (Batch), each 5x5 spatial size, with 3 channels\n",
                "batch_size = 10\n",
                "height = 5\n",
                "width = 5\n",
                "channels = 3\n",
                "\n",
                "pooled_feature_maps = np.random.rand(batch_size, height, width, channels)\n",
                "print(\"Shape before flattening:\", pooled_feature_maps.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Implementing Flattening\n",
                "We can use NumPy's `reshape` function."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Shape after flattening: (10, 75)\n",
                        "Each image is now a vector of size 75\n"
                    ]
                }
            ],
            "source": [
                "# The target shape should be (Batch_Size, Total_Features)\n",
                "total_features = height * width * channels\n",
                "\n",
                "flattened_output = pooled_feature_maps.reshape(batch_size, total_features)\n",
                "\n",
                "print(\"Shape after flattening:\", flattened_output.shape)\n",
                "print(f\"Each image is now a vector of size {total_features}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Full Connection (Dense Layer)\n",
                "A Dense layer performs: $Output = Activation(Dot(Input, Weights) + Bias)$\n",
                "\n",
                "Let's simulate a layer with 10 neurons (e.g., for 10 digits in MNIST)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Output shape of Dense Layer: (10, 10)\n"
                    ]
                }
            ],
            "source": [
                "# Define Weights and Biases randomly\n",
                "num_neurons = 10\n",
                "weights = np.random.rand(total_features, num_neurons)\n",
                "bias = np.random.rand(num_neurons)\n",
                "\n",
                "# Apply Dense Layer Operation\n",
                "# (10, 75) dot (75, 10) -> (10, 10)\n",
                "dense_output = np.dot(flattened_output, weights) + bias\n",
                "\n",
                "print(\"Output shape of Dense Layer:\", dense_output.shape)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
